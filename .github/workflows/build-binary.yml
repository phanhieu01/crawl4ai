name: Build Binary

on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:
    inputs:
      version:
        description: 'Version tag (e.g., v0.8.0)'
        required: false
        default: 'latest'

jobs:
  build:
    strategy:
      matrix:
        os: [ubuntu-20.04]
        include:
          - os: ubuntu-20.04
            os_name: linux
            binary_ext: ''
            binary_name: crawl4ai

    runs-on: ${{ matrix.os }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libnss3-dev libatk-bridge2.0-dev libdrm2 libxkbcommon0 libgbm1 libasound2

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyinstaller

      - name: Install crawl4ai
        run: |
          pip install -e .

      - name: Install Playwright browsers
        run: |
          playwright install --with-deps chromium
          playwright install chrome

      - name: Build binary
        run: |
          pyinstaller crawl4ai/cli.py \
            --name crawl4ai \
            --onefile \
            --console \
            --clean \
            --add-data "crawl4ai/js_snippet:crawl4ai/js_snippet" \
            --hidden-import crawl4ai.async_webcrawler \
            --hidden-import crawl4ai.async_crawler_strategy \
            --hidden-import crawl4ai.browser_manager \
            --hidden-import crawl4ai.extraction_strategy \
            --hidden-import crawl4ai.markdown_generation_strategy \
            --hidden-import crawl4ai.chunking_strategy \
            --hidden-import crawl4ai.content_filter_strategy \
            --hidden-import crawl4ai.content_scraping_strategy \
            --hidden-import crawl4ai.deep_crawling \
            --hidden-import crawl4ai.adaptive_crawler \
            --hidden-import crawl4ai.cache_context \
            --hidden-import crawl4ai.async_database \
            --hidden-import playwright \
            --hidden-import aiohttp \
            --hidden-import aiofiles \
            --hidden-import lxml \
            --hidden-import beautifulsoup4 \
            --hidden-import PIL \
            --hidden-import pydantic \
            --hidden-import yaml \
            --collect-all playwright \
            --collect-all patchright \
            --strip \
            --optimize 2

      - name: Create archive
        run: |
          cd dist
          tar -czf crawl4ai-${{ matrix.os_name }}-amd64.tar.gz crawl4ai${{ matrix.binary_ext }}

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: crawl4ai-${{ matrix.os_name }}-amd64
          path: dist/crawl4ai-${{ matrix.os_name }}-amd64.tar.gz
          retention-days: 90

  release:
    needs: build
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          files: |
            artifacts/crawl4ai-linux-amd64/crawl4ai-linux-amd64.tar.gz
          draft: false
          prerelease: false
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
